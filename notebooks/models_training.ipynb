{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from models.train_full import train, test\n",
    "from models.models import CNNClassifier, ResNetClassifier\n",
    "from models.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pretty(ld, indent=0):\n",
    "    with open('result.txt', 'w', encoding='utf-8') as file:\n",
    "        for d in tqdm(ld):\n",
    "            file.write('{' + '\\n')\n",
    "            for key, value in d.items():\n",
    "                file.write('\\t' * (indent+1) + str(key) + ':' + str(value) + '\\n')\n",
    "                # file.write('\\t' * (indent+1) + str(key) + '\\n')\n",
    "                # file.write('\\t' * (indent+2) + str(value) + '\\n')\n",
    "            file.write('},\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "do_train = True\n",
    "\n",
    "seed = 4444\n",
    "\n",
    "metric_filter_1 = 'val_mcc'\n",
    "metric_filter_2 = 'val_mae'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_model = dict(\n",
    "    # dictionary with model information\n",
    "    in_channels=[3],\n",
    "    out_channels=[2],\n",
    "    # dim_layers=[[32, 64, 128], [16, 32, 64]],\n",
    "    dim_layers=[[32, 64, 128]],\n",
    "    # block_conv_layers=[3, 5],\n",
    "    block_conv_layers=[3],\n",
    "    residual=[True],\n",
    "    # max_pooling=[True, False],\n",
    "    max_pooling=[True],\n",
    "    transforms=[\n",
    "        (\n",
    "            '0',\n",
    "            torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomResizedCrop(size=(400, 400)),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "            ]),\n",
    "            torchvision.transforms.Resize(size=(400, 400)),\n",
    "            # transforms.RandomResizedCrop(size=(400, 400)),\n",
    "            # test varios times over the same data and choose the mean\n",
    "            False,\n",
    "        ),\n",
    "        (\n",
    "            '1',\n",
    "            torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(size=(400, 400)),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "            ]),\n",
    "            torchvision.transforms.Resize(size=(400, 400)),\n",
    "            True,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        \n",
    "        d = d.copy()\n",
    "        transforms = d.pop('transforms')\n",
    "\n",
    "        train(\n",
    "            model=CNNClassifier(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=\"./logs_full\",\n",
    "            data_path=\"../data_full\",\n",
    "            save_path=\"./models/saved_full\",\n",
    "            lr=1e-2,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=150,\n",
    "            batch_size=32,\n",
    "            num_workers=2,\n",
    "            scheduler_mode='min_mse',\n",
    "            debug_mode=False,\n",
    "            device=None,\n",
    "            steps_save=15,\n",
    "            use_cpu=False,\n",
    "            loss_age_weight=1e-2,\n",
    "            scheduler_patience=30,\n",
    "            train_transforms=transforms[1],\n",
    "            test_transforms=transforms[2],\n",
    "            suffix=transforms[0],\n",
    "            use_cache=transforms[3],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [54:07<00:00, 162.37s/it] \n"
     ]
    }
   ],
   "source": [
    "res_test = test(\n",
    "    data_path = \"../data_full\",\n",
    "    save_path = './models/saved_full',\n",
    "    n_runs = 1,\n",
    "    batch_size = 64,\n",
    "    num_workers = 0,\n",
    "    debug_mode = False,\n",
    "    use_cpu = False,\n",
    "    save = True,\n",
    "    verbose = False,\n",
    "    transforms=torchvision.transforms.Resize(size=(400, 400)),\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 3,\n",
       " 'out_channels': 2,\n",
       " 'dim_layers': [32, 64, 128],\n",
       " 'block_conv_layers': 3,\n",
       " 'residual': True,\n",
       " 'max_pooling': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 135,\n",
       " 'train_loss': 0.7180283,\n",
       " 'val_mse_age': 131.51015,\n",
       " 'train_acc': 0.9394927024841309,\n",
       " 'val_acc': 0.8674965500831604,\n",
       " 'val_mcc': 0.7339866991692735,\n",
       " 'model_class': 'cnn',\n",
       " 'path_name': '3_2_[32_64_128]_3_True_True_0.01_adamw_32_min_mse_0.01_1_135',\n",
       " 'train_mae': 5.088548,\n",
       " 'val_mae': 8.730115,\n",
       " 'test_mae': 8.740539,\n",
       " 'train_mse': 42.900738,\n",
       " 'val_mse': 131.44864,\n",
       " 'test_mse': 136.33107,\n",
       " 'train_mcc': 0.8789576593001115,\n",
       " 'test_mcc': 0.7426456711701096,\n",
       " 'test_acc': 0.8714404106140137}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 3,\n",
       " 'out_channels': 2,\n",
       " 'dim_layers': [32, 64, 128],\n",
       " 'block_conv_layers': 3,\n",
       " 'residual': True,\n",
       " 'max_pooling': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 120,\n",
       " 'train_loss': 0.88590217,\n",
       " 'val_mse_age': 127.54852,\n",
       " 'train_acc': 0.9190470576286316,\n",
       " 'val_acc': 0.8652835488319397,\n",
       " 'val_mcc': 0.7305876856123024,\n",
       " 'model_class': 'cnn',\n",
       " 'path_name': '3_2_[32_64_128]_3_True_True_0.01_adamw_32_min_mse_0.01_1_120',\n",
       " 'train_mae': 5.7857547,\n",
       " 'val_mae': 8.650999,\n",
       " 'test_mae': 8.628361,\n",
       " 'train_mse': 56.060917,\n",
       " 'val_mse': 127.48625,\n",
       " 'test_mse': 133.53343,\n",
       " 'train_mcc': 0.8400896585159275,\n",
       " 'test_mcc': 0.7315739561738387,\n",
       " 'test_acc': 0.8645285964012146}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_model = dict(\n",
    "    # dictionary with model information\n",
    "    in_channels=[3],\n",
    "    out_channels=[2],\n",
    "    dim_layers=[[32, 64, 128], [16, 32, 64]],\n",
    "    block_conv_layers=[3],\n",
    "    residual=[True],\n",
    "    max_pooling=[True, False],\n",
    "    transforms=[\n",
    "        (\n",
    "            '1',\n",
    "            torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(size=(400, 400)),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "            ]),\n",
    "            torchvision.transforms.Resize(size=(400, 400)),\n",
    "            True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        \n",
    "        d = d.copy()\n",
    "        transforms = d.pop('transforms')\n",
    "\n",
    "        train(\n",
    "            model=CNNClassifier(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=\"./logs_full_2\",\n",
    "            data_path=\"../data_full\",\n",
    "            save_path=\"./models/saved_full_2\",\n",
    "            lr=1e-2,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=200,\n",
    "            batch_size=32,\n",
    "            num_workers=3,\n",
    "            scheduler_mode='min_mse',\n",
    "            debug_mode=False,\n",
    "            device=None,\n",
    "            steps_save=15,\n",
    "            use_cpu=False,\n",
    "            loss_age_weight=1e-2,\n",
    "            scheduler_patience=30,\n",
    "            train_transforms=transforms[1],\n",
    "            test_transforms=transforms[2],\n",
    "            suffix=transforms[0],\n",
    "            use_cache=transforms[3],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [53:13<00:00, 122.81s/it] \n"
     ]
    }
   ],
   "source": [
    "res_test = test(\n",
    "    data_path = \"../data_full\",\n",
    "    save_path = './models/saved_full_2',\n",
    "    n_runs = 1,\n",
    "    batch_size = 64,\n",
    "    num_workers = 0,\n",
    "    debug_mode = False,\n",
    "    use_cpu = False,\n",
    "    save = True,\n",
    "    verbose = False,\n",
    "    transforms=torchvision.transforms.Resize(size=(400, 400)),\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 3,\n",
       " 'out_channels': 2,\n",
       " 'dim_layers': [32, 64, 128],\n",
       " 'block_conv_layers': 3,\n",
       " 'residual': True,\n",
       " 'max_pooling': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 120,\n",
       " 'train_loss': 0.3935543,\n",
       " 'val_mse_age': 154.79866,\n",
       " 'train_acc': 0.9855399131774902,\n",
       " 'val_acc': 0.8511756658554077,\n",
       " 'val_mcc': 0.7011677685312916,\n",
       " 'model_class': 'cnn',\n",
       " 'path_name': '3_2_[32_64_128]_3_True_True_0.01_adamw_32_min_mse_0.01_1_120',\n",
       " 'train_mae': 3.5678704,\n",
       " 'val_mae': 9.337749,\n",
       " 'test_mae': 9.498872,\n",
       " 'train_mse': 20.937126,\n",
       " 'val_mse': 154.50348,\n",
       " 'test_mse': 162.88927,\n",
       " 'train_mcc': 0.9710754062237904,\n",
       " 'test_mcc': 0.7199835661808924,\n",
       " 'test_acc': 0.8598285913467407}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 3,\n",
       " 'out_channels': 2,\n",
       " 'dim_layers': [32, 64, 128],\n",
       " 'block_conv_layers': 3,\n",
       " 'residual': True,\n",
       " 'max_pooling': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 120,\n",
       " 'train_loss': 0.3935543,\n",
       " 'val_mse_age': 154.79866,\n",
       " 'train_acc': 0.9855399131774902,\n",
       " 'val_acc': 0.8511756658554077,\n",
       " 'val_mcc': 0.7011677685312916,\n",
       " 'model_class': 'cnn',\n",
       " 'path_name': '3_2_[32_64_128]_3_True_True_0.01_adamw_32_min_mse_0.01_1_120',\n",
       " 'train_mae': 3.5678704,\n",
       " 'val_mae': 9.337749,\n",
       " 'test_mae': 9.498872,\n",
       " 'train_mse': 20.937126,\n",
       " 'val_mse': 154.50348,\n",
       " 'test_mse': 162.88927,\n",
       " 'train_mcc': 0.9710754062237904,\n",
       " 'test_mcc': 0.7199835661808924,\n",
       " 'test_acc': 0.8598285913467407}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_model = dict(\n",
    "    # dictionary with model information\n",
    "    in_channels=[3],\n",
    "    out_channels=[2],\n",
    "    dim_layers=[[32, 64, 128], [16, 32, 64]],\n",
    "    block_conv_layers=[3, 5],\n",
    "    residual=[True],\n",
    "    max_pooling=[True],\n",
    "    transforms=[\n",
    "        (\n",
    "            '1',\n",
    "            torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(size=(200, 200)),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "            ]),\n",
    "            torchvision.transforms.Resize(size=(200, 200)),\n",
    "            True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "in_channels=3/out_channels=2/dim_layers=[32/64/128]/block_conv_layers=3/residual=True/max_pooling=True/train_lr=0.01/train_optimizer_name=adamw/train_batch_size=32/train_scheduler_mode=min_mse/train_loss_age_weight=0.01/train_suffix=1 -> 142.6066436767578: 100%|██████████| 150/150 [4:32:08<00:00, 108.86s/it]\n",
      "in_channels=3/out_channels=2/dim_layers=[32/64/128]/block_conv_layers=5/residual=True/max_pooling=True/train_lr=0.01/train_optimizer_name=adamw/train_batch_size=32/train_scheduler_mode=min_mse/train_loss_age_weight=0.01/train_suffix=1 -> 136.85464477539062: 100%|██████████| 150/150 [5:57:56<00:00, 143.18s/it]\n",
      "in_channels=3/out_channels=2/dim_layers=[16/32/64]/block_conv_layers=3/residual=True/max_pooling=True/train_lr=0.01/train_optimizer_name=adamw/train_batch_size=32/train_scheduler_mode=min_mse/train_loss_age_weight=0.01/train_suffix=1 -> 164.13406372070312: 100%|██████████| 150/150 [2:21:44<00:00, 56.69s/it]\n",
      "in_channels=3/out_channels=2/dim_layers=[16/32/64]/block_conv_layers=5/residual=True/max_pooling=True/train_lr=0.01/train_optimizer_name=adamw/train_batch_size=32/train_scheduler_mode=min_mse/train_loss_age_weight=0.01/train_suffix=1 -> 153.98013305664062: 100%|██████████| 150/150 [2:54:01<00:00, 69.61s/it]\n",
      "100%|██████████| 4/4 [15:45:55<00:00, 14188.98s/it]  \n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        \n",
    "        d = d.copy()\n",
    "        transforms = d.pop('transforms')\n",
    "\n",
    "        train(\n",
    "            model=CNNClassifier(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=\"./logs_full_3\",\n",
    "            data_path=\"../data_full\",\n",
    "            save_path=\"./models/saved_full_3\",\n",
    "            lr=1e-2,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=150,\n",
    "            batch_size=32,\n",
    "            num_workers=3,\n",
    "            scheduler_mode='min_mse',\n",
    "            debug_mode=False,\n",
    "            device=None,\n",
    "            steps_save=15,\n",
    "            use_cpu=False,\n",
    "            loss_age_weight=1e-2,\n",
    "            scheduler_patience=50,\n",
    "            train_transforms=transforms[1],\n",
    "            test_transforms=transforms[2],\n",
    "            suffix=transforms[0],\n",
    "            use_cache=transforms[3],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [30:18<00:00, 45.47s/it]  \n"
     ]
    }
   ],
   "source": [
    "res_test = test(\n",
    "    data_path = \"../data_full\",\n",
    "    save_path = './models/saved_full_3',\n",
    "    n_runs = 1,\n",
    "    batch_size = 64,\n",
    "    num_workers = 0,\n",
    "    debug_mode = False,\n",
    "    use_cpu = False,\n",
    "    save = True,\n",
    "    verbose = False,\n",
    "    transforms=torchvision.transforms.Resize(size=(200, 200)),\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 3,\n",
       " 'out_channels': 2,\n",
       " 'dim_layers': [32, 64, 128],\n",
       " 'block_conv_layers': 5,\n",
       " 'residual': True,\n",
       " 'max_pooling': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 135,\n",
       " 'train_loss': 0.09937081,\n",
       " 'val_mse_age': 136.1627,\n",
       " 'train_acc': 0.9453597068786621,\n",
       " 'val_acc': 0.8691563010215759,\n",
       " 'val_mcc': 0.7393854840096149,\n",
       " 'model_class': 'cnn',\n",
       " 'path_name': '3_2_[32_64_128]_5_True_True_0.01_adamw_32_min_mse_0.01_1_135',\n",
       " 'train_mae': 4.7501335,\n",
       " 'val_mae': 8.544613,\n",
       " 'test_mae': 8.676856,\n",
       " 'train_mse': 61.469128,\n",
       " 'val_mse': 135.64902,\n",
       " 'test_mse': 140.35268,\n",
       " 'train_mcc': 0.8905810254413973,\n",
       " 'test_mcc': 0.7558911097519115,\n",
       " 'test_acc': 0.8777992725372314}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_channels': 3,\n",
       " 'out_channels': 2,\n",
       " 'dim_layers': [32, 64, 128],\n",
       " 'block_conv_layers': 5,\n",
       " 'residual': True,\n",
       " 'max_pooling': True,\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 135,\n",
       " 'train_loss': 0.09937081,\n",
       " 'val_mse_age': 136.1627,\n",
       " 'train_acc': 0.9453597068786621,\n",
       " 'val_acc': 0.8691563010215759,\n",
       " 'val_mcc': 0.7393854840096149,\n",
       " 'model_class': 'cnn',\n",
       " 'path_name': '3_2_[32_64_128]_5_True_True_0.01_adamw_32_min_mse_0.01_1_135',\n",
       " 'train_mae': 4.7501335,\n",
       " 'val_mae': 8.544613,\n",
       " 'test_mae': 8.676856,\n",
       " 'train_mse': 61.469128,\n",
       " 'val_mse': 135.64902,\n",
       " 'test_mse': 140.35268,\n",
       " 'train_mcc': 0.8905810254413973,\n",
       " 'test_mcc': 0.7558911097519115,\n",
       " 'test_acc': 0.8777992725372314}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "])\n",
    "\n",
    "dict_model = dict(\n",
    "    # dictionary with model information\n",
    "    out_channels=[2],\n",
    "    resnet_arch=['resnet101'],\n",
    "    transforms=[\n",
    "        (\n",
    "            '1',\n",
    "            resnet_transform,\n",
    "            resnet_transform,\n",
    "            True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "list_model = [dict(zip(dict_model.keys(), k)) for k in itertools.product(*dict_model.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "out_channels=2/resnet_arch=resnet101/train_lr=0.01/train_optimizer_name=adamw/train_batch_size=32/train_scheduler_mode=min_mse/train_loss_age_weight=0.01/train_suffix=1 -> 129.66549682617188: 100%|██████████| 50/50 [4:02:28<00:00, 290.97s/it]\n",
      "100%|██████████| 1/1 [4:02:29<00:00, 14549.29s/it]\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    for d in tqdm(list_model):\n",
    "        set_seed(seed)\n",
    "        \n",
    "        d = d.copy()\n",
    "        transforms = d.pop('transforms')\n",
    "\n",
    "        train(\n",
    "            model=ResNetClassifier(**d),\n",
    "            dict_model=d,\n",
    "            log_dir=\"./logs_full_4\",\n",
    "            data_path=\"../data_full\",\n",
    "            save_path=\"./models/saved_full_4\",\n",
    "            lr=1e-2,\n",
    "            optimizer_name=\"adamw\",\n",
    "            n_epochs=50,\n",
    "            batch_size=32,\n",
    "            num_workers=3,\n",
    "            scheduler_mode='min_mse',\n",
    "            debug_mode=False,\n",
    "            device=None,\n",
    "            steps_save=1,\n",
    "            use_cpu=False,\n",
    "            loss_age_weight=1e-2,\n",
    "            scheduler_patience=15,\n",
    "            train_transforms=transforms[1],\n",
    "            test_transforms=transforms[2],\n",
    "            suffix=transforms[0],\n",
    "            use_cache=transforms[3],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "  2%|▏         | 1/50 [02:31<2:03:28, 151.20s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "  4%|▍         | 2/50 [04:37<1:49:06, 136.39s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "  6%|▌         | 3/50 [06:44<1:43:25, 132.04s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "  8%|▊         | 4/50 [08:50<1:39:29, 129.77s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 10%|█         | 5/50 [10:56<1:36:26, 128.60s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 12%|█▏        | 6/50 [13:03<1:33:46, 127.87s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 14%|█▍        | 7/50 [15:09<1:31:12, 127.27s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 16%|█▌        | 8/50 [17:15<1:28:54, 127.00s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 18%|█▊        | 9/50 [19:21<1:26:31, 126.63s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 20%|██        | 10/50 [21:27<1:24:15, 126.38s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 22%|██▏       | 11/50 [23:33<1:22:03, 126.25s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 24%|██▍       | 12/50 [25:40<1:20:05, 126.46s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 26%|██▌       | 13/50 [27:46<1:17:54, 126.35s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 28%|██▊       | 14/50 [29:52<1:15:45, 126.27s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 30%|███       | 15/50 [31:58<1:13:39, 126.26s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 32%|███▏      | 16/50 [34:04<1:11:29, 126.17s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 34%|███▍      | 17/50 [36:10<1:09:21, 126.10s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 36%|███▌      | 18/50 [38:16<1:07:11, 125.99s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 38%|███▊      | 19/50 [40:22<1:05:05, 125.99s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 40%|████      | 20/50 [42:28<1:03:01, 126.07s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 42%|████▏     | 21/50 [44:34<1:00:54, 126.03s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 44%|████▍     | 22/50 [46:40<58:49, 126.06s/it]  Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 46%|████▌     | 23/50 [48:47<56:48, 126.23s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 48%|████▊     | 24/50 [50:53<54:41, 126.20s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 50%|█████     | 25/50 [52:59<52:31, 126.08s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 52%|█████▏    | 26/50 [55:05<50:25, 126.05s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 54%|█████▍    | 27/50 [57:11<48:20, 126.12s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 56%|█████▌    | 28/50 [59:17<46:14, 126.11s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 58%|█████▊    | 29/50 [1:01:23<44:06, 126.03s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 60%|██████    | 30/50 [1:03:29<42:00, 126.03s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 62%|██████▏   | 31/50 [1:05:35<39:55, 126.09s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 64%|██████▍   | 32/50 [1:07:41<37:48, 126.05s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 66%|██████▌   | 33/50 [1:09:47<35:42, 126.03s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 68%|██████▊   | 34/50 [1:11:55<33:43, 126.47s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 70%|███████   | 35/50 [1:14:01<31:36, 126.42s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 72%|███████▏  | 36/50 [1:16:07<29:29, 126.36s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 74%|███████▍  | 37/50 [1:18:13<27:22, 126.33s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 76%|███████▌  | 38/50 [1:20:20<25:15, 126.28s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 78%|███████▊  | 39/50 [1:22:26<23:08, 126.24s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 80%|████████  | 40/50 [1:24:32<21:02, 126.23s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 82%|████████▏ | 41/50 [1:26:38<18:56, 126.28s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 84%|████████▍ | 42/50 [1:28:45<16:50, 126.31s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 86%|████████▌ | 43/50 [1:30:51<14:43, 126.23s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 88%|████████▊ | 44/50 [1:32:57<12:36, 126.16s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 90%|█████████ | 45/50 [1:35:03<10:31, 126.28s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 92%|█████████▏| 46/50 [1:37:09<08:24, 126.22s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 94%|█████████▍| 47/50 [1:39:16<06:19, 126.34s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 96%|█████████▌| 48/50 [1:41:23<04:12, 126.47s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 98%|█████████▊| 49/50 [1:43:29<02:06, 126.37s/it]Using cache found in C:\\Users\\vibal/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "100%|██████████| 50/50 [1:45:35<00:00, 126.71s/it]\n"
     ]
    }
   ],
   "source": [
    "res_test = test(\n",
    "    data_path = \"../data_full\",\n",
    "    save_path = './models/saved_full_4',\n",
    "    n_runs = 1,\n",
    "    batch_size = 32,\n",
    "    num_workers = 0,\n",
    "    debug_mode = False,\n",
    "    use_cpu = False,\n",
    "    save = True,\n",
    "    verbose = False,\n",
    "    transforms=resnet_transform,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_channels': 2,\n",
       " 'resnet_arch': 'resnet101',\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 43,\n",
       " 'train_loss': 0.6081334,\n",
       " 'val_mse_age': 123.5416,\n",
       " 'train_acc': 0.9404408931732178,\n",
       " 'val_acc': 0.8481327891349792,\n",
       " 'val_mcc': 0.6951585259600446,\n",
       " 'model_class': 'resnet',\n",
       " 'path_name': '2_resnet101_0.01_adamw_32_min_mse_0.01_1_43',\n",
       " 'train_mae': 4.006076,\n",
       " 'val_mae': 7.922617,\n",
       " 'test_mae': 8.46471,\n",
       " 'train_mse': 27.257505,\n",
       " 'val_mse': 123.513016,\n",
       " 'test_mse': 141.31798,\n",
       " 'train_mcc': 0.8806601359748256,\n",
       " 'test_mcc': 0.6936917666320735,\n",
       " 'test_acc': 0.8471108675003052}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_1] for k in all])[::-1]\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_channels': 2,\n",
       " 'resnet_arch': 'resnet101',\n",
       " 'train_lr': 0.01,\n",
       " 'train_optimizer_name': 'adamw',\n",
       " 'train_batch_size': 32,\n",
       " 'train_scheduler_mode': 'min_mse',\n",
       " 'train_loss_age_weight': 0.01,\n",
       " 'train_suffix': '1',\n",
       " 'epoch': 44,\n",
       " 'train_loss': 0.5390967,\n",
       " 'val_mse_age': 123.270744,\n",
       " 'train_acc': 0.946485698223114,\n",
       " 'val_acc': 0.844260036945343,\n",
       " 'val_mcc': 0.6893895235738362,\n",
       " 'model_class': 'resnet',\n",
       " 'path_name': '2_resnet101_0.01_adamw_32_min_mse_0.01_1_44',\n",
       " 'train_mae': 3.7745793,\n",
       " 'val_mae': 7.897413,\n",
       " 'test_mae': 8.395246,\n",
       " 'train_mse': 24.130426,\n",
       " 'val_mse': 123.282555,\n",
       " 'test_mse': 139.65997,\n",
       " 'train_mcc': 0.8933645503982973,\n",
       " 'test_mcc': 0.6855484187139131,\n",
       " 'test_acc': 0.8421343564987183}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = res_test\n",
    "# ascending order\n",
    "sort_idx = np.argsort([k['dict'][metric_filter_2] for k in all])\n",
    "all[sort_idx[0]]['dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37be9487e307834247f9cc00a1ec46ceeb3f522b7edf17e3b2d74c6ce713e314"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
